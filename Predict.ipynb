{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "986fba5c-1059-40a3-b9a0-46965355a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, random, re, json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "import ast\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Could not find the number of physical cores\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a7a4bc-6d6f-48ad-8f98-54d53497f1a2",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16dc0c2b-31a3-40d4-abbc-77c4751d9ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing model\n",
    "with open(\"model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "\n",
    "BASE = \"https://www.aruodas.lt/butu-nuoma/vilniuje/puslapis/{page}/\"\n",
    "\n",
    "# A small pool of real-world browser UAs\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "      \"Chrome/115.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "      \"AppleWebKit/605.1.15 (KHTML, like Gecko) \"\n",
    "      \"Version/14.1.2 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) \"\n",
    "      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "      \"Chrome/114.0.0.0 Safari/537.36\",\n",
    "]\n",
    "\n",
    "# Extended headers to mimic a real browser\n",
    "COMMON_HEADERS = {\n",
    "    \"Accept\":                    \"text/html,application/xhtml+xml,application/xml;\"\n",
    "                                 \"q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Accept-Language\":           \"en-GB,en;q=0.9\",\n",
    "    \"Accept-Encoding\":           \"gzip, deflate, br\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"Referer\":                   \"https://www.aruodas.lt/\",\n",
    "    \"Connection\":                \"keep-alive\",\n",
    "    \"Sec-Fetch-Site\":            \"same-origin\",\n",
    "    \"Sec-Fetch-Mode\":            \"navigate\",\n",
    "    \"Sec-Fetch-Dest\":            \"document\",\n",
    "}\n",
    "\n",
    "def make_session():\n",
    "    sess = requests.Session()\n",
    "    sess.headers.update(COMMON_HEADERS)\n",
    "    # Prime cookies or JS challenges\n",
    "    sess.get(\"https://www.aruodas.lt/butu-nuoma/vilniuje/\", timeout=5)\n",
    "    return sess\n",
    "\n",
    "def _parse_dl_block(dl):\n",
    "    \"\"\"\n",
    "    Extract <dt>/<dd> pairs from a <dl> block.\n",
    "    Returns a dict of {key: [values]}.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    if not dl:\n",
    "        return out\n",
    "    for dt in dl.find_all(\"dt\"):\n",
    "        key = dt.get_text(strip=True).rstrip(\":\")\n",
    "        dd  = dt.find_next_sibling(\"dd\")\n",
    "        if not dd:\n",
    "            continue\n",
    "\n",
    "        spans = [s.get_text(strip=True) for s in dd.find_all(\"span\") if s.get_text(strip=True)]\n",
    "        if spans:\n",
    "            out[key] = spans\n",
    "        else:\n",
    "            text = dd.get_text(strip=True)\n",
    "            out[key] = [text] if text else []\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_primary_heating_dummies(df, source_col=\"Šildymas\"):\n",
    "    \"\"\"\n",
    "    From df[source_col] (list or JSON-string list of heating types), extract\n",
    "    the first word of the first list entry and one-hot encode:\n",
    "      - Centrinis\n",
    "      - Dujinis\n",
    "      - Elektra\n",
    "    using 'Kita' as the reference (i.e. no dummy for 'Kita').\n",
    "\n",
    "    Returns a new DataFrame with the dummy columns added.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def get_primary(s):\n",
    "        if pd.isna(s):\n",
    "            return \"Kita\"\n",
    "        # Case 1: already a list\n",
    "        if isinstance(s, (list, tuple, set)):\n",
    "            items = list(s)\n",
    "        else:\n",
    "            # Case 2: string\n",
    "            try:\n",
    "                items = json.loads(s)\n",
    "            except Exception:\n",
    "                try:\n",
    "                    items = ast.literal_eval(str(s))\n",
    "                except Exception:\n",
    "                    return \"Kita\"\n",
    "        if not items:\n",
    "            return \"Kita\"\n",
    "        first = str(items[0])\n",
    "        # grab the first token before space or comma\n",
    "        m = re.match(r\"^([^ ,]+)\", first)\n",
    "        return m.group(1) if m else \"Kita\"\n",
    "\n",
    "    # 1) build a Series of the primary heating type\n",
    "    prim = df[source_col].map(get_primary).astype(\"category\")\n",
    "\n",
    "    # 2) manually create dummies for the 3 you want\n",
    "    df = df.copy()\n",
    "    df[\"heat_Centrinis\"] = (prim == \"Centrinis\").astype(int)\n",
    "    df[\"heat_Dujinis\"]   = (prim == \"Dujinis\").astype(int)\n",
    "    df[\"heat_Elektra\"]   = (prim == \"Elektra\").astype(int)\n",
    "\n",
    "    # 'Kita' is the implicit case when all three are 0\n",
    "    return df\n",
    "\n",
    "def add_window_orientation_dummies(df, source_col=\"Langų orientacija\"):\n",
    "    \"\"\"\n",
    "    From df[source_col] (JSON‑string lists of orientations), extract\n",
    "    the first word of the first list entry (Pietūs, Vakarai, Rytai, Šiaurė, etc.),\n",
    "    then one‑hot encode:\n",
    "      - orient_Pietus\n",
    "      - orient_Vakarai\n",
    "      - orient_Rytai\n",
    "    using 'Šiaurė' as the implicit reference (all zeros).\n",
    "    \"\"\"\n",
    "    def get_primary_orient(s):\n",
    "        if pd.isna(s):\n",
    "            return \"Šiaurė\"\n",
    "        try:\n",
    "            items = json.loads(s)\n",
    "            if not items:\n",
    "                return \"Šiaurė\"\n",
    "            first = items[0]\n",
    "            # grab the first token before space or comma\n",
    "            m = re.match(r\"^([^ ,]+)\", first)\n",
    "            return m.group(1) if m else \"Šiaurė\"\n",
    "        except Exception:\n",
    "            return \"Šiaurė\"\n",
    "\n",
    "    prim = df[source_col].map(get_primary_orient).astype(\"category\")\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"orient_Pietus\"] = (prim == \"Pietūs\").astype(int)\n",
    "    out[\"orient_Vakarai\"] = (prim == \"Vakarai\").astype(int)\n",
    "    out[\"orient_Rytai\"]  = (prim == \"Rytai\").astype(int)\n",
    "    # Šiaurė is the reference (when all three dummies are zero)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c501bc3a-a187-4c5d-b7ff-9e44443614b2",
   "metadata": {},
   "source": [
    "### Defining new functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "325f4c76-3b13-411c-a1d7-33c8c4a9b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _first_value(d, col):\n",
    "    \"\"\"Return the first value for `col` (handles list/tuple/str).\"\"\"\n",
    "    v = d.get(col, pd.Series([None])).iloc[0]\n",
    "    if isinstance(v, (list, tuple, set)):\n",
    "        v = list(v)[0] if len(v) else None\n",
    "    return v\n",
    "\n",
    "def _parse_number(text):\n",
    "    \"\"\"Return float from text like '129 m²' or '45,5 m²'; NaN if none.\"\"\"\n",
    "    if text is None or (isinstance(text, float) and pd.isna(text)):\n",
    "        return np.nan\n",
    "    s = str(text).replace(\"\\u00A0\", \" \").replace(\",\", \".\")\n",
    "    m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", s)\n",
    "    return float(m.group(0)) if m else np.nan\n",
    "\n",
    "def _extract_location_from_title(soup):\n",
    "    \"\"\"\n",
    "    Parse <h1 class=\"obj-header-text\">Vilnius, Žirmūnai, Olimpiečių g., ...</h1>\n",
    "    → return (city, district, street).\n",
    "    \"\"\"\n",
    "    h1 = soup.select_one(\"h1.obj-header-text\")\n",
    "    if not h1:\n",
    "        return None, None, None\n",
    "\n",
    "    # Get clean text\n",
    "    txt = h1.get_text(\" \", strip=True)\n",
    "\n",
    "    # Keep only the part before 'buto nuoma' (or similar trailing phrase)\n",
    "    # e.g. \"Vilnius, Žirmūnai, Olimpiečių g.\"\n",
    "    head = re.split(r\"\\b(buto|būsto)\\s+nuoma\\b\", txt, flags=re.IGNORECASE)[0]\n",
    "\n",
    "    # Split by commas and strip\n",
    "    parts = [p.strip(\" ,\") for p in head.split(\",\") if p.strip(\" ,\")]\n",
    "\n",
    "    # Expect at least 3 parts: city, district, street\n",
    "    city     = parts[0] if len(parts) >= 1 else None\n",
    "    district = parts[1] if len(parts) >= 2 else None\n",
    "    street   = parts[2] if len(parts) >= 3 else None\n",
    "    return city, district, street\n",
    "\n",
    "\n",
    "# def scrape_listing(url, session=None):\n",
    "#     if session is None:\n",
    "#         session = make_session()\n",
    "#     session.headers['User-Agent'] = random.choice(USER_AGENTS)\n",
    "#     resp = session.get(url, timeout=10)\n",
    "#     resp.raise_for_status()\n",
    "#     soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "#     # --- parse main obj-details ---\n",
    "#     details = _parse_dl_block(soup.find(\"dl\", class_=\"obj-details\"))\n",
    "\n",
    "#     # --- parse obj-stats (Įdėtas, Redaguotas, Aktyvus iki, etc.) ---\n",
    "#     stats = _parse_dl_block(soup.find(\"div\", class_=\"obj-stats\").find(\"dl\"))\n",
    "\n",
    "#     # merge them\n",
    "#     details.update(stats)\n",
    "\n",
    "#     out = {\"url\": url}\n",
    "#     out.update(details)\n",
    "#     return out\n",
    "\n",
    "def scrape_listing(url, session=None):\n",
    "    if session is None:\n",
    "        session = make_session()\n",
    "    session.headers['User-Agent'] = random.choice(USER_AGENTS)\n",
    "    resp = session.get(url, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    # Parse both <dl> blocks\n",
    "    details = _parse_dl_block(soup.find(\"dl\", class_=\"obj-details\"))\n",
    "    stats   = _parse_dl_block(soup.find(\"div\", class_=\"obj-stats\").find(\"dl\")) if soup.find(\"div\", class_=\"obj-stats\") else {}\n",
    "    details.update(stats)\n",
    "\n",
    "    # NEW: city / district / street from header\n",
    "    city, district, street = _extract_location_from_title(soup)\n",
    "    if city:     details[\"city\"]     = [city]\n",
    "    if district: details[\"district\"] = [district]\n",
    "    if street:   details[\"street\"]   = [street]\n",
    "\n",
    "    out = {\"url\": url}\n",
    "    out.update(details)\n",
    "    return out\n",
    "\n",
    "# centre of Vilnius\n",
    "city_center = (54.6872, 25.2797)\n",
    "\n",
    "# single shared geocoder + a tiny cache\n",
    "_geocoder = Nominatim(user_agent=\"rent_model_geocoder\", timeout=10)\n",
    "_GEOCODE_CACHE = {}\n",
    "\n",
    "def _geocode_addr(addr: str):\n",
    "    if not addr:\n",
    "        return None, None\n",
    "    if addr in _GEOCODE_CACHE:\n",
    "        return _GEOCODE_CACHE[addr]\n",
    "    try:\n",
    "        loc = _geocoder.geocode(addr)\n",
    "        if loc:\n",
    "            _GEOCODE_CACHE[addr] = (loc.latitude, loc.longitude)\n",
    "            return loc.latitude, loc.longitude\n",
    "    except Exception:\n",
    "        pass\n",
    "    _GEOCODE_CACHE[addr] = (None, None)\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def featurise(raw_dict):\n",
    "    \"\"\"\n",
    "    Take one scraped listing (dict) and transform into model-ready features.\n",
    "    Replicates your training logic but tolerates missing fields.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([raw_dict])\n",
    "\n",
    "    # ---- Ensure columns exist (create with safe defaults) ----\n",
    "    # columns that are list-like in training\n",
    "    listlike_defaults = {\n",
    "        \"Šildymas\": [],\n",
    "        \"Ypatybės\": [],\n",
    "        \"Papildomos patalpos\": [],\n",
    "        # \"Langų orientacija\": []   # keep only if you still use it\n",
    "    }\n",
    "    for col, default in listlike_defaults.items():\n",
    "        if col not in df.columns:\n",
    "            df[col] = [json.dumps(default)]  # your downstream uses json.loads\n",
    "        else:\n",
    "            # normalise: if it's already a list, turn into JSON string for consistency\n",
    "            if isinstance(df.at[df.index[0], col], (list, tuple, set)):\n",
    "                df[col] = df[col].map(lambda v: json.dumps(list(v), ensure_ascii=False))\n",
    "\n",
    "    # ---- Clean/convert columns used by your model ----\n",
    "    df['Metai'] = (\n",
    "        df.get('Metai', pd.Series([None]))\n",
    "          .astype(str).str.extract(r'(\\d{4})', expand=False).astype(float)\n",
    "    )\n",
    "    df['year_centered'] = df['Metai'] - 2000\n",
    "\n",
    "    # Heating dummies (robust version you just adopted)\n",
    "    df = add_primary_heating_dummies(df)\n",
    "\n",
    "    # If you kept window orientation, wrap it with a missing-column guard\n",
    "    # df = add_window_orientation_dummies(df)  # only if still in your feature set\n",
    "\n",
    "    # has_lift\n",
    "    df['has_lift'] = (\n",
    "        df['Ypatybės']\n",
    "          .map(lambda s: 'Yra liftas' in (json.loads(s) if pd.notnull(s) else []))\n",
    "          .astype(int)\n",
    "    )\n",
    "\n",
    "    # has_balcony_terrace\n",
    "    df['has_balcony_terrace'] = (\n",
    "        df['Papildomos patalpos']\n",
    "          .map(lambda s: any(x in {'Balkonas','Terasa'} for x in (json.loads(s) if pd.notnull(s) else [])))\n",
    "          .astype(int)\n",
    "    )\n",
    "\n",
    "    # has_parking_spot\n",
    "    df['has_parking_spot'] = (\n",
    "        df['Papildomos patalpos']\n",
    "          .map(lambda s: 'Vieta automobiliui' in (json.loads(s) if pd.notnull(s) else []))\n",
    "          .astype(int)\n",
    "    )\n",
    "\n",
    "    # --- Build address → geocode → distance ---\n",
    "    city     = _first_value(df, \"city\") or \"Vilnius\"\n",
    "    district = _first_value(df, \"district\")\n",
    "    street   = _first_value(df, \"street\")\n",
    "    house    = _first_value(df, \"Namo numeris\")  \n",
    "\n",
    "    lat = df.get('latitude', pd.Series([None])).iloc[0]\n",
    "    lon = df.get('longitude', pd.Series([None])).iloc[0]\n",
    "\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        # 1. First try with district\n",
    "        parts_with = [p for p in [city, district, street] if p]\n",
    "        base_with = \", \".join(parts_with)\n",
    "        addr_with = f\"{base_with} {house}\" if (base_with and house) else base_with\n",
    "\n",
    "        lat, lon = _geocode_addr(addr_with)\n",
    "        if (lat is None or lon is None) and house:\n",
    "            lat, lon = _geocode_addr(base_with)\n",
    "\n",
    "        # 2. If still nothing, retry WITHOUT district\n",
    "        if (lat is None or lon is None):\n",
    "            parts_no = [p for p in [city, street] if p]\n",
    "            base_no = \", \".join(parts_no)\n",
    "            addr_no = f\"{base_no} {house}\" if (base_no and house) else base_no\n",
    "\n",
    "            lat, lon = _geocode_addr(addr_no)\n",
    "            if (lat is None or lon is None) and house:\n",
    "                lat, lon = _geocode_addr(base_no)\n",
    "\n",
    "    df[\"latitude\"]  = lat\n",
    "    df[\"longitude\"] = lon\n",
    "    df[\"dist_to_center_km\"] = (\n",
    "        geodesic((lat, lon), city_center).km\n",
    "        if pd.notnull(lat) and pd.notnull(lon) else np.nan)\n",
    "\n",
    "    # --- Įdėtas → age_days ---\n",
    "    posted_txt = _first_value(df, \"Įdėtas\")   # e.g. \"2025-08-18\"\n",
    "    \n",
    "    try:\n",
    "        posted_date = pd.to_datetime(str(posted_txt), errors=\"coerce\")\n",
    "        if pd.notnull(posted_date):\n",
    "            today = pd.to_datetime(datetime.today().date())\n",
    "            df[\"age_days\"] = (today - posted_date).days   # <-- no .dt\n",
    "        else:\n",
    "            df[\"age_days\"] = np.nan\n",
    "    except Exception:\n",
    "        df[\"age_days\"] = np.nan\n",
    "\n",
    "    # --- Plotas → area_m2 ---\n",
    "    pl_txt = _first_value(df, \"Plotas\")   # e.g. \"129 m²\" or \"45,5 m²\"\n",
    "    df[\"area_m2\"] = _parse_number(pl_txt)\n",
    "\n",
    "    # --- Aukštų sk. → floor_total ---\n",
    "    ft_txt = _first_value(df, \"Aukštų sk.\")   # e.g. [5] or \"5\"\n",
    "    df[\"floor_total\"] = _parse_number(ft_txt)\n",
    "\n",
    "    # --- Aukštas → floor_current ---\n",
    "    fc_txt = _first_value(df, \"Aukštas\")   # e.g. [3] or \"3\"\n",
    "    df[\"floor_current\"] = _parse_number(fc_txt)\n",
    "\n",
    "    # --- Kambarių sk. → rooms ---\n",
    "    rm_txt = _first_value(df, \"Kambarių sk.\")   # e.g. [3] or \"3\"\n",
    "    df[\"rooms\"] = _parse_number(rm_txt)\n",
    "\n",
    "\n",
    "    # Final feature list (without orientation, per your last decision)\n",
    "    numeric_feats = [\n",
    "        'rooms','floor_current','floor_total','age_days','area_m2',\n",
    "        'year_centered','dist_to_center_km',\n",
    "        'heat_Centrinis','heat_Dujinis','heat_Elektra',\n",
    "        'has_lift','has_balcony_terrace','has_parking_spot'\n",
    "    ]\n",
    "\n",
    "    # Ensure presence, fill missing numerics with NaN → your model/pipe should handle or you can fill here\n",
    "    for col in numeric_feats:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "    \n",
    "\n",
    "    nice = (\n",
    "        df[numeric_feats]\n",
    "          .T.rename_axis(\"Feature\")\n",
    "          .reset_index()\n",
    "          .rename(columns={0: \"Value\"})\n",
    "    )\n",
    "    \n",
    "    display(\n",
    "        nice.style\n",
    "            .format({\"Value\": \"{:.2f}\"})\n",
    "            .set_properties(subset=[\"Feature\"], **{\"font-weight\": \"600\"})\n",
    "            .hide(axis=\"index\")  # removes the default 0..N index\n",
    "    )\n",
    "    \n",
    "    return df[numeric_feats]\n",
    "\n",
    "\n",
    "def predict_from_url(url, model, session=None):\n",
    "    raw = scrape_listing(url, session=session)\n",
    "    feats = featurise(raw)\n",
    "    X = feats  # LightGBM version (no const)\n",
    "    pred_pm2 = model.predict(X)[0]\n",
    "\n",
    "    # total price\n",
    "    area = feats[\"area_m2\"].iloc[0]\n",
    "    total_price = pred_pm2 * area if pd.notnull(area) else None\n",
    "    return pred_pm2, total_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a0ce232-9984-4270-9e9d-5ed775f7b0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_25714_row0_col0, #T_25714_row1_col0, #T_25714_row2_col0, #T_25714_row3_col0, #T_25714_row4_col0, #T_25714_row5_col0, #T_25714_row6_col0, #T_25714_row7_col0, #T_25714_row8_col0, #T_25714_row9_col0, #T_25714_row10_col0, #T_25714_row11_col0, #T_25714_row12_col0 {\n",
       "  font-weight: 600;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_25714\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_25714_level0_col0\" class=\"col_heading level0 col0\" >Feature</th>\n",
       "      <th id=\"T_25714_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row0_col0\" class=\"data row0 col0\" >rooms</td>\n",
       "      <td id=\"T_25714_row0_col1\" class=\"data row0 col1\" >3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row1_col0\" class=\"data row1 col0\" >floor_current</td>\n",
       "      <td id=\"T_25714_row1_col1\" class=\"data row1 col1\" >3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row2_col0\" class=\"data row2 col0\" >floor_total</td>\n",
       "      <td id=\"T_25714_row2_col1\" class=\"data row2 col1\" >5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row3_col0\" class=\"data row3 col0\" >age_days</td>\n",
       "      <td id=\"T_25714_row3_col1\" class=\"data row3 col1\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row4_col0\" class=\"data row4 col0\" >area_m2</td>\n",
       "      <td id=\"T_25714_row4_col1\" class=\"data row4 col1\" >129.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row5_col0\" class=\"data row5 col0\" >year_centered</td>\n",
       "      <td id=\"T_25714_row5_col1\" class=\"data row5 col1\" >6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row6_col0\" class=\"data row6 col0\" >dist_to_center_km</td>\n",
       "      <td id=\"T_25714_row6_col1\" class=\"data row6 col1\" >0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row7_col0\" class=\"data row7 col0\" >heat_Centrinis</td>\n",
       "      <td id=\"T_25714_row7_col1\" class=\"data row7 col1\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row8_col0\" class=\"data row8 col0\" >heat_Dujinis</td>\n",
       "      <td id=\"T_25714_row8_col1\" class=\"data row8 col1\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row9_col0\" class=\"data row9 col0\" >heat_Elektra</td>\n",
       "      <td id=\"T_25714_row9_col1\" class=\"data row9 col1\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row10_col0\" class=\"data row10 col0\" >has_lift</td>\n",
       "      <td id=\"T_25714_row10_col1\" class=\"data row10 col1\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row11_col0\" class=\"data row11 col0\" >has_balcony_terrace</td>\n",
       "      <td id=\"T_25714_row11_col1\" class=\"data row11 col1\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25714_row12_col0\" class=\"data row12 col0\" >has_parking_spot</td>\n",
       "      <td id=\"T_25714_row12_col1\" class=\"data row12 col1\" >0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17578d1ca70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price/m²: 15.74 EUR/m²\n",
      "Predicted total monthly rent: 2030 EUR\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", None)   # show all columns\n",
    "pd.set_option(\"display.max_rows\", None)      # show all rows (careful with large dfs)\n",
    "pd.set_option(\"display.width\", 1000)         # widen the printout so it doesn't wrap\n",
    "\n",
    "url = \"https://www.aruodas.lt/butu-nuoma-vilniuje-zirmunuose-olimpieciu-g-ypatingai-patogioje-vietoje-karaliaus-4-1304811/?search_pos=3\"\n",
    "\n",
    "pred_price_pm2, total_price = predict_from_url(url, model)\n",
    "\n",
    "print(f\"Predicted price/m²: {pred_price_pm2:.2f} EUR/m²\")\n",
    "print(f\"Predicted total monthly rent: {total_price:.0f} EUR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f69cd66-fabd-44d8-8875-4a2d9b77ca0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d85bb_row0_col0, #T_d85bb_row1_col0, #T_d85bb_row2_col0, #T_d85bb_row3_col0, #T_d85bb_row4_col0, #T_d85bb_row5_col0, #T_d85bb_row6_col0, #T_d85bb_row7_col0, #T_d85bb_row8_col0, #T_d85bb_row9_col0, #T_d85bb_row10_col0, #T_d85bb_row11_col0, #T_d85bb_row12_col0 {\n",
       "  font-weight: 600;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d85bb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_d85bb_level0_col0\" class=\"col_heading level0 col0\" >Feature</th>\n",
       "      <th id=\"T_d85bb_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row0_col0\" class=\"data row0 col0\" >rooms</td>\n",
       "      <td id=\"T_d85bb_row0_col1\" class=\"data row0 col1\" >2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row1_col0\" class=\"data row1 col0\" >floor_current</td>\n",
       "      <td id=\"T_d85bb_row1_col1\" class=\"data row1 col1\" >2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row2_col0\" class=\"data row2 col0\" >floor_total</td>\n",
       "      <td id=\"T_d85bb_row2_col1\" class=\"data row2 col1\" >5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row3_col0\" class=\"data row3 col0\" >age_days</td>\n",
       "      <td id=\"T_d85bb_row3_col1\" class=\"data row3 col1\" >547.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row4_col0\" class=\"data row4 col0\" >area_m2</td>\n",
       "      <td id=\"T_d85bb_row4_col1\" class=\"data row4 col1\" >55.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row5_col0\" class=\"data row5 col0\" >year_centered</td>\n",
       "      <td id=\"T_d85bb_row5_col1\" class=\"data row5 col1\" >-4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row6_col0\" class=\"data row6 col0\" >dist_to_center_km</td>\n",
       "      <td id=\"T_d85bb_row6_col1\" class=\"data row6 col1\" >5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row7_col0\" class=\"data row7 col0\" >heat_Centrinis</td>\n",
       "      <td id=\"T_d85bb_row7_col1\" class=\"data row7 col1\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row8_col0\" class=\"data row8 col0\" >heat_Dujinis</td>\n",
       "      <td id=\"T_d85bb_row8_col1\" class=\"data row8 col1\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row9_col0\" class=\"data row9 col0\" >heat_Elektra</td>\n",
       "      <td id=\"T_d85bb_row9_col1\" class=\"data row9 col1\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row10_col0\" class=\"data row10 col0\" >has_lift</td>\n",
       "      <td id=\"T_d85bb_row10_col1\" class=\"data row10 col1\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row11_col0\" class=\"data row11 col0\" >has_balcony_terrace</td>\n",
       "      <td id=\"T_d85bb_row11_col1\" class=\"data row11 col1\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d85bb_row12_col0\" class=\"data row12 col0\" >has_parking_spot</td>\n",
       "      <td id=\"T_d85bb_row12_col1\" class=\"data row12 col1\" >0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17578d1ca70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price/m²: 9.74 EUR/m²\n",
      "Predicted total monthly rent: 536 EUR\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.aruodas.lt/butu-nuoma-vilniuje-baltupiuose-baltupio-g-isnuomojamas-sviesus-ir-siltas-ju-kambariu-4-1275570/?search_pos=12\"\n",
    "pred_price_pm2, total_price = predict_from_url(url, model)\n",
    "\n",
    "print(f\"Predicted price/m²: {pred_price_pm2:.2f} EUR/m²\")\n",
    "print(f\"Predicted total monthly rent: {total_price:.0f} EUR\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
